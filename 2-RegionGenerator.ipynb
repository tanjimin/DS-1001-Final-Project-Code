{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as linear_model\n",
    "import datetime as dt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../../Project/data/201804-citibike-tripdata.csv\")\n",
    "data2 = pd.read_csv(\"../../Project/data/201805-citibike-tripdata.csv\")\n",
    "data3 = pd.read_csv(\"../../Project/data/201806-citibike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval = pd.read_csv(\"../../Project/data/201807-citibike-tripdata.csv\")\n",
    "data_test = pd.read_csv(\"../../Project/data/201808-citibike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data1,data2,data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption functions\n",
    "\n",
    "def get_duration(station1, station2):\n",
    "    return 0\n",
    "\n",
    "def user_end_distribution(data):\n",
    "    # Station id and outflow percentage\n",
    "    outflow_distribution = {'id': 0}\n",
    "    return distribution\n",
    "\n",
    "# get data from data frame\n",
    "# return a list of all data\n",
    "# start_time_min/max must be datetime objects\n",
    "def get_unlock_data(start_time_min, start_time_max, start_station, full_data):\n",
    "    if type(start_time_min) != dt.datetime or type(start_time_max) != dt.datetime:\n",
    "        raise TypeError('Not datetime object.')\n",
    "    data_for_station = full_data[full_data['start_station_id'] == start_station]\n",
    "    data_list = data_for_station[data_for_station['start_time'] > start_time_min]\n",
    "    data_list = data_for_station[data_for_station['start_time'] < start_time_max]\n",
    "    return data_list\n",
    "\n",
    "# subtract duration(minutes) from time correclty\n",
    "def subtract_time(time, input_minutes):\n",
    "    if type(time) != dt.datetime:\n",
    "        raise TypeError('Not datetime object.')\n",
    "    datetime_minutes = timedelta(minutes = input_minutes)\n",
    "    adjusted_minutes = time - datetime_minutes\n",
    "    return adjusted_minutes\n",
    "\n",
    "# add duration(minutes) to time correclty\n",
    "def add_time(time, input_minutes):\n",
    "    if type(time) != dt.datetime:\n",
    "        raise TypeError('Not datetime object.')\n",
    "    datetime_minutes = timedelta(minutes = input_minutes)\n",
    "    adjusted_minutes = time + datetime_minutes\n",
    "    return adjusted_minutes\n",
    "\n",
    "# Compare time\n",
    "def smaller_than_time(time1, time2):\n",
    "    if type(time1) != dt.datetime or type(time2) != dt.datetime:\n",
    "        raise TypeError('Not datetime object.')\n",
    "    return time1 < time2\n",
    "\n",
    "def get_historical_inflow(start_station, end_station, end_time):\n",
    "    ##\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_stations: a list of all stations\n",
    "# interval: mins (+- 10 mins)\n",
    "def calculate_inflow(predTime, curTime, end_station, all_stations, interval):\n",
    "    ## look up how to calculate time\n",
    "    # Calculate distribution for all stations\n",
    "    inflow = 0\n",
    "    for start_station in all_stations:\n",
    "        trip_duration = get_duration(start_station, end_station)\n",
    "        start_time = subtract_time(predTime, trip_duration)\n",
    "        # use historical data if now is earlier than start time:\n",
    "        if smaller_than_time(predTime, start_time):\n",
    "            inflow += get_historical_inflow(start_station, end_station, predTime)\n",
    "        else:\n",
    "            unlock_list = get_unlock_data(subtract_time(start_time, interval / 2), \n",
    "                                          add_time(start_time, interval / 2),\n",
    "                                          start_station)\n",
    "            # add inflow for every user from the same start station\n",
    "            for unlocked_user in unlock_list:\n",
    "                inflow += user_end_distribution(unlocked_user)[end_station]\n",
    "    return inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    \n",
    "    def __init__(self, x, y, swap = True):\n",
    "        if swap:\n",
    "            self.x = y\n",
    "            self.y = x\n",
    "        else:\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "        \n",
    "class Line:\n",
    "    \n",
    "    def __init__(self, p1, p2):\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.a = (p1.y - p2.y) / (p1.x - p2.x)\n",
    "        self.b = p1.y - self.a * p1.x\n",
    "        \n",
    "    def getY(self, x):\n",
    "        return self.a * x + self.b\n",
    "        \n",
    "    def getX(self, y):\n",
    "        return (y - self.b) / self.a\n",
    "    \n",
    "    def above(self, input_point):\n",
    "        return input_point.y >= self.getY(input_point.x)\n",
    "    \n",
    "    def below(self, input_point):\n",
    "        return input_point.y < self.getY(input_point.x)\n",
    "    \n",
    "    def right(self, input_point):\n",
    "        return input_point.x >= self.getX(input_point.y)\n",
    "        \n",
    "    def left(self, input_point):\n",
    "        return input_point.x < self.getX(input_point.y)\n",
    "    \n",
    "class Region:\n",
    "    \n",
    "    def __init__(self, line_left, line_right, line_down, line_up, num):\n",
    "        self.line_left = line_left\n",
    "        self.line_right = line_right\n",
    "        self.line_up = line_up\n",
    "        self.line_down = line_down\n",
    "        self.num = num\n",
    "        \n",
    "    def check_inside(self, point):\n",
    "        return self.line_left.right(point) and \\\n",
    "               self.line_right.left(point) and \\\n",
    "               self.line_up.below(point) and \\\n",
    "               self.line_down.above(point)\n",
    "    \n",
    "    def get_num(self):\n",
    "        return self.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_v1 = Line(Point(40.822042, -73.960223), Point(40.733240, -74.019613))\n",
    "line_v2 = Line(Point(40.815704, -73.947402), Point(40.706711, -74.024827))\n",
    "line_v3 = Line(Point(40.811526, -73.938080), Point(40.701839, -74.017955))\n",
    "line_v4 = Line(Point(40.804877, -73.923991), Point(40.696625, -74.004297))\n",
    "line_v5 = Line(Point(40.729934, -73.961664), Point(40.705813, -73.980607))\n",
    "\n",
    "line_h11 = Line(Point(40.822042, -73.960223), Point(40.804877, -73.923991))\n",
    "line_h10 = Line(Point(40.805881, -73.970669), Point(40.790774, -73.932337))\n",
    "line_h9 = Line(Point(40.795345, -73.978905), Point(40.779025, -73.940987))\n",
    "line_h8 = Line(Point(40.783599, -73.987055), Point(40.768406, -73.949353))\n",
    "line_h7 = Line(Point(40.773192, -73.994511), Point(40.758769, -73.958902))\n",
    "line_h6 = Line(Point(40.762348, -74.002173), Point(40.747673, -73.967231))\n",
    "line_h5 = Line(Point(40.750092, -74.010230), Point(40.729934, -73.961664))\n",
    "line_h4 = Line(Point(40.743822, -74.015333), Point(40.725047, -73.965458))\n",
    "line_h3 = Line(Point(40.733240, -74.019613), Point(40.718461, -73.972046))\n",
    "line_h2 = Line(Point(40.721485, -74.015598), Point(40.705813, -73.980607))\n",
    "line_h1 = Line(Point(40.706711, -74.024827), Point(40.696625, -74.004297))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = []\n",
    "\n",
    "regions.append(Region(line_v2, line_v3, line_h1, line_h2, 1))\n",
    "regions.append(Region(line_v3, line_v4, line_h1, line_h2, 2))\n",
    "regions.append(Region(line_v2, line_v3, line_h2, line_h3, 3))\n",
    "regions.append(Region(line_v3, line_v4, line_h2, line_h3, 4))\n",
    "regions.append(Region(line_v4, line_v5, line_h2, line_h3, 5))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h3, line_h4, 6))\n",
    "regions.append(Region(line_v2, line_v3, line_h3, line_h4, 7))\n",
    "regions.append(Region(line_v3, line_v4, line_h3, line_h4, 8))\n",
    "regions.append(Region(line_v4, line_v5, line_h3, line_h4, 9))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h4, line_h5, 10))\n",
    "regions.append(Region(line_v2, line_v3, line_h4, line_h5, 11))\n",
    "regions.append(Region(line_v3, line_v4, line_h4, line_h5, 12))\n",
    "regions.append(Region(line_v4, line_v5, line_h4, line_h5, 13))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h5, line_h6, 14))\n",
    "regions.append(Region(line_v2, line_v3, line_h5, line_h6, 15))\n",
    "regions.append(Region(line_v3, line_v4, line_h5, line_h6, 16))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h6, line_h7, 17))\n",
    "regions.append(Region(line_v2, line_v3, line_h6, line_h7, 18))\n",
    "regions.append(Region(line_v3, line_v4, line_h6, line_h7, 19))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h7, line_h8, 20))\n",
    "regions.append(Region(line_v2, line_v3, line_h7, line_h8, 21))\n",
    "regions.append(Region(line_v3, line_v4, line_h7, line_h8, 22))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h8, line_h9, 23))\n",
    "regions.append(Region(line_v2, line_v3, line_h8, line_h9, 24))\n",
    "regions.append(Region(line_v3, line_v4, line_h8, line_h9, 25))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h9, line_h10, 26))\n",
    "regions.append(Region(line_v2, line_v3, line_h9, line_h10, 27))\n",
    "regions.append(Region(line_v3, line_v4, line_h9, line_h10, 28))\n",
    "\n",
    "regions.append(Region(line_v1, line_v2, line_h10, line_h11, 29))\n",
    "regions.append(Region(line_v2, line_v3, line_h10, line_h11, 30))\n",
    "regions.append(Region(line_v3, line_v4, line_h10, line_h11, 31))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_for_point(regions, lat, long):\n",
    "    point_test = Point(lat,long)\n",
    "    # Testing purpose\n",
    "    region_num = []\n",
    "    for region in regions:\n",
    "        if region.check_inside(point_test):\n",
    "            region_num.append(region.get_num())\n",
    "    if len(region_num) > 1:\n",
    "        raise Exception('Multiple values for', region_num)\n",
    "    else:\n",
    "        if len(region_num) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return region_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_region_list = []\n",
    "for i in range(data.shape[0]):\n",
    "    start_region_list.append(region_for_point(regions, data['start station latitude'].iloc[i], data['start station longitude'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_region_list = []\n",
    "for i in range(data.shape[0]):\n",
    "    end_region_list.append(region_for_point(regions, data['end station latitude'].iloc[i], data['end station longitude'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_region_list_eval = []\n",
    "for i in range(data_eval.shape[0]):\n",
    "    start_region_list_eval.append(region_for_point(regions, data_eval['start station latitude'].iloc[i], data_eval['start station longitude'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_region_list_eval = []\n",
    "for i in range(data_eval.shape[0]):\n",
    "    end_region_list_eval.append(region_for_point(regions, data_eval['end station latitude'].iloc[i], data_eval['end station longitude'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_region_list_test = []\n",
    "for i in range(data_test.shape[0]):\n",
    "    start_region_list_test.append(region_for_point(regions, data_test['start station latitude'].iloc[i], data_test['start station longitude'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_region_list_test = []\n",
    "for i in range(data_test.shape[0]):\n",
    "    end_region_list_test.append(region_for_point(regions, data_test['end station latitude'].iloc[i], data_test['end station longitude'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['start region'] = start_region_list\n",
    "data['end region'] = end_region_list\n",
    "data_eval['start region'] = start_region_list_eval\n",
    "data_eval['end region'] = end_region_list_eval\n",
    "data_test['start region'] = start_region_list_test\n",
    "data_test['end region'] = end_region_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_train.csv')\n",
    "data_eval.to_csv('data_val.csv')\n",
    "data_test.to_csv('data_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
